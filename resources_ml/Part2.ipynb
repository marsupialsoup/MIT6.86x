








<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <title>Jupyter Notebook Viewer</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">
  
  <meta name="robots" content="noindex,nofollow">
  

  <!--NEW RELIC Start Perf Measurement-->
  
  <!--NREND-->

  <!-- Le styles -->
  <link href="/static/build/styles.css?v=55ba354138253381d2c0ada9821cd4da" rel="stylesheet">

  <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
  <!--[if lt IE 9]>
    <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->

  <!-- Le fav and touch icons -->
  <link rel="shortcut icon" href="/static/ico/ipynb_icon_16x16.png">
  <link rel="apple-touch-icon-precomposed" sizes="144x144"
        href="/static/ico/apple-touch-icon-144-precomposed.png?v=5a3c9ede93e2a8b8ea9e3f8f3da1a905">
  <link rel="apple-touch-icon-precomposed" sizes="114x114"
        href="/static/ico/apple-touch-icon-114-precomposed.png?v=45d86fc8f24dc00638035e1dd7a6d898">
  <link rel="apple-touch-icon-precomposed" sizes="72x72"
        href="/static/ico/apple-touch-icon-72-precomposed.png?v=540b5eb0f3cfd25f1439d1c9bd30e15f">
  <link rel="apple-touch-icon-precomposed"
        href="/static/ico/apple-touch-icon-57-precomposed.png?v=225f0590e187e1458625654f10a28f56">
  
  

  

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Notebook on nbviewer">
  <meta name="twitter:description" content="Check out this Jupyter notebook!">

  
  <meta name="twitter:domain" content="nbviewer.jupyter.org">
  <meta name="twitter:image:src" content="http://ipython.org/ipython-doc/dev/_images/ipynb_icon_128x128.png">

  
    <link href="/static/build/notebook.css?v=aae8f92f7e80fc468ae446b9d852fe90" rel="stylesheet">
  

  

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML" type="text/javascript">
    </script>
    <script type="text/javascript">
      init_mathjax = function() {
        if (window.MathJax) {
          // MathJax loaded
          MathJax.Hub.Config({
            TeX: {
              equationNumbers: {
                autoNumber: "AMS",
                useLabelIds: true
              }
            },
            tex2jax: {
              inlineMath: [ ['$','$'], ["\\(","\\)"] ],
              displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
              processEscapes: true,
              processEnvironments: true
            },
            displayAlign: 'center',
            "HTML-CSS": {
              styles: {'.MathJax_Display': {"margin": 0}},
              linebreaks: { automatic: true }
            }
          });
          MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
      }
      init_mathjax();
    </script>
  

  
    <script>
      (function() {
        function addWidgetsRenderer() {
          var mimeElement = document.querySelector('script[type="application/vnd.jupyter.widget-view+json"]');
          var scriptElement = document.createElement('script');
          var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@0.15/dist/embed-amd.js';
          var widgetState;

          try {
            widgetState = mimeElement && JSON.parse(mimeElement.innerHTML);

            if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) {
              widgetRendererSrc = 'https://unpkg.com/jupyter-js-widgets@2.1/dist/embed.js';
            }
          } catch(e) {}

          scriptElement.src = widgetRendererSrc;
          document.body.appendChild(scriptElement);
        }

        document.addEventListener('DOMContentLoaded', addWidgetsRenderer);
      }());
    </script>
  

</head>

<body class="nbviewer">

  <!-- These are loaded at the top of the body so they are available to
       notebook cells when they are loaded below. -->
  <script src="/static/components/jquery/dist/jquery.min.js?v=220afd743d9e9643852e31a135a9f3ae"></script>
  <script src="/static/components/requirejs/require.js?v=6da8be361b9ee26c5e721e76c6d4afce"></script>
  <script src="/static/components/moment/min/moment.min.js?v=89f87298ad94aa1e6b92f42eb66da043"></script>
<!-- Navbar
================================================== -->
  <nav id="menubar" class="navbar navbar-default navbar-fixed-top" data-spy="affix">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse">
          <span class="sr-only">Toggle navigation</span>
          <i class="fa fa-bars"></i>
        </button>
        <a class="navbar-brand" href="/">
          <img src="/static/img/nav_logo.svg?v=479cefe8d932fb14a67b93911b97d70f" width="159"/>
        </a>
      </div>

      <div class="collapse navbar-collapse">
        <ul class="nav navbar-nav navbar-right">
          <li>
            <a class="active" href="https://jupyter.org">JUPYTER</a>
          </li>
          <li>
    <a href="/faq" title="FAQ" >
      
        <span>FAQ</span>
      
    </a>
  </li>

          
  
    
  
    
      
        <li>
    <a href="/format/script/github/Varal7/ml-tutorial/blob/master/Part2.ipynb" title="View as Code" >
      <span class="fa fa-code fa-2x menu-icon"></span>
      <span class="menu-text">View as Code</span>
    </a>
  </li>
      
    
  

  
    <li>
    <a href="#" title="Python 3 Kernel" >
      <span class="fa fa-server fa-2x menu-icon"></span>
      <span class="menu-text">Python 3 Kernel</span>
    </a>
  </li>
  

  
    <li>
    <a href="https://github.com/Varal7/ml-tutorial/blob/master/Part2.ipynb" title="View on GitHub" >
      <span class="fa fa-github fa-2x menu-icon"></span>
      <span class="menu-text">View on GitHub</span>
    </a>
  </li>
  

  
    <li>
    <a href="https://mybinder.org/v2/gh/Varal7/ml-tutorial/master?filepath=Part2.ipynb" title="Execute on Binder" >
      <span class="fa fa-icon-binder fa-2x menu-icon"></span>
      <span class="menu-text">Execute on Binder</span>
    </a>
  </li>
  

  <li>
    <a href="https://raw.githubusercontent.com/Varal7/ml-tutorial/master/Part2.ipynb" title="Download Notebook" download>
      <span class="fa fa-download fa-2x menu-icon"></span>
      <span class="menu-text">Download Notebook</span>
    </a>
  </li>

        </ul>
      </div><!-- /.navbar-collapse -->
      
      
    </div>
  </nav>

  <div class="container container-main">
    
  
  <ol class="breadcrumb">
    
      <li>
        <a href="/github/Varal7/ml-tutorial/tree/master">ml-tutorial</a>
      </li>
    
      <li>
        <a href="/github/Varal7/ml-tutorial/tree/master/Part2.ipynb">Part2.ipynb</a>
      </li>
    
  </ol>
  
  <div id="notebook">
    <div id="notebook-container">
      <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="6.86x---Introduction-to-ML-Packages-(Part-2)">6.86x - Introduction to ML Packages (Part 2)<a class="anchor-link" href="#6.86x---Introduction-to-ML-Packages-(Part-2)">&#182;</a></h1><p>This tutorial is designed to provide a short introduction to deep learning with PyTorch.</p>
<p>You can start studying this tutorial as you work through unit 3 of the course.
For more resources, check out <a href="https://pytorch.org/tutorials/">the PyTorch tutorials</a>! There are many more in-depth examples available there.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Source code for this notebook hosted at: <a href="https://github.com/varal7/ml-tutorial">https://github.com/varal7/ml-tutorial</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="PyTorch">PyTorch<a class="anchor-link" href="#PyTorch">&#182;</a></h2><p><a href="https://pytorch.org">PyTorch</a> is a flexible scientific computing package targetted towards gradient-based deep learning. Its low-level API closely follows <a href="https://www.numpy.org/">NumPy</a>. However, there are a several key additions:</p>
<ul>
<li>GPU support!</li>
<li>Automatic differentiation!</li>
<li>Deep learning modules!</li>
<li>Data loading!</li>
<li>And other generally useful goodies.</li>
</ul>
<p>If you don't have GPU enabled hardward, don't worry. Like NumPy, PyTorch runs pre-compiled, highly efficient C code to handle all intensive backend functions.</p>
<p>Go to pytorch.org to download the correct package for your computing environment.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Start by importing torch</span>
<span class="kn">import</span> <span class="nn">torch</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Tensors">Tensors<a class="anchor-link" href="#Tensors">&#182;</a></h3><p>Tensors are PyTorch's equivalent of NumPy ndarrays.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Construct a bunch of ones</span>
<span class="n">some_ones</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">some_ones</span><span class="p">)</span>

<span class="c1"># Construct a bunch of zeros</span>
<span class="n">some_zeros</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">some_zeros</span><span class="p">)</span>

<span class="c1"># Construct some normally distributed values</span>
<span class="n">some_normals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">some_normals</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([[1., 1.],
        [1., 1.]])
tensor([[0., 0.],
        [0., 0.]])
tensor([[-2.4514, -0.6150],
        [ 0.9997,  0.4635]])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>PyTorch tensors and NumPy ndarrays even share the same memory handles, so you can switch between the two types essentially for free:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">torch_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">numpy_ndarray</span> <span class="o">=</span> <span class="n">torch_tensor</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">back_to_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">numpy_ndarray</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Like NumPy, there are a zillion different operations you can do with tensors. Best thing to do is to go to <a href="https://pytorch.org/docs/stable/tensors.html">https://pytorch.org/docs/stable/tensors.html</a> if you know you want to do something to a tensor but don't know how!</p>
<p>We can cover a few major ones here:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the Numpy tutorial, we have covered the basics of Numpy, numpy arrays, element-wise operations, matrices operations and generating random matrices. 
In this section, we'll cover indexing, slicing and broadcasting, which are useful concepts that will be reused in <code>Pandas</code> and <code>PyTorch</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Create two tensors</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([[-2.4792,  0.7683, -0.8724, -1.0555, -1.3677],
        [ 0.2659,  0.3905,  0.4132,  1.0330,  1.3572],
        [-0.3723, -0.8348, -1.1457, -1.4766, -1.0380],
        [ 1.7401,  1.5151, -0.6725, -0.8755,  0.2736],
        [ 0.9129,  0.9838, -0.8510, -0.2960, -0.3731]])
tensor([[ 0.7255,  0.7353, -0.5352,  1.4629, -0.4881],
        [-1.2316,  0.7042, -1.3126,  0.8110, -1.3477],
        [-2.4669,  0.0770,  0.9740,  0.4297, -0.5245],
        [-1.0458, -1.2261,  0.6324,  0.8264, -1.3746],
        [-2.2290,  0.1202, -0.4826, -1.9797, -0.0879]])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Indexing by i,j</span>
<span class="n">another_tensor</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">another_tensor</span><span class="p">)</span>

<span class="c1"># The above returns a tensor type! To get the python value:</span>
<span class="n">python_value</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">python_value</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor(-1.1457)
-1.1456899642944336
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Getting a whole row or column or range</span>
<span class="n">first_row</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">first_column</span> <span class="o">=</span> <span class="n">a</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">combo</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">combo</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([[-1.1457, -1.4766],
        [-0.6725, -0.8755]])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Addition</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>

<span class="c1"># Elementwise multiplication: c_ij = a_ij * b_ij</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">b</span>

<span class="c1"># Matrix multiplication: c_ik = a_ij * b_jk</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

<span class="c1"># Matrix vector multiplication</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">b</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

<span class="n">vec</span> <span class="o">=</span> <span class="n">a</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vec</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

<span class="c1"># Matrix multiple 5x5 * 5x5 --&gt; 5x5</span>
<span class="n">aa</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="c1"># matrix vector 5x5 * 5 --&gt; 5</span>
<span class="n">v1</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">vec</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">v1</span><span class="p">)</span>


<span class="n">vec_as_matrix</span> <span class="o">=</span> <span class="n">vec</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">v2</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">vec_as_matrix</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">v2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([5, 5])
torch.Size([5])
tensor([ 3.8873,  2.8224,  0.5655, -1.8550,  3.2441])
tensor([[ 3.8873],
        [ 2.8224],
        [ 0.5655],
        [-1.8550],
        [ 3.2441]])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In-place operations exist to, generally denoted by a trailing '_' (e.g. my_tensor.my_inplace<em>function</em>).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Add one to all elements</span>
<span class="n">a</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Divide all elements by 2</span>
<span class="n">a</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Set all elements to 0</span>
<span class="n">a</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[12]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>tensor([[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Manipulate dimensions...</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Add a dummy dimension, e.g. (n, m) --&gt; (n, m, 1)</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="c1"># At the end</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

<span class="c1"># At the beginning</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

<span class="c1"># In the middle</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

<span class="c1"># What you give you can take away</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

<span class="c1"># View things differently, i.e. flat</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

<span class="c1"># Or not flat</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

<span class="c1"># Copy data across a new dummy dimension!</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([10, 10, 1])
torch.Size([1, 10, 10])
torch.Size([10, 1, 10])
torch.Size([10, 10])
torch.Size([100, 1])
torch.Size([50, 2])
tensor([[-0.1561],
        [ 0.1588]])
tensor([[-0.1561, -0.1561, -0.1561],
        [ 0.1588,  0.1588,  0.1588]])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If you have a GPU...</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Check if you have it</span>
<span class="n">do_i_have_cuda</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>

<span class="k">if</span> <span class="n">do_i_have_cuda</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Using fancy GPUs&#39;</span><span class="p">)</span>
    <span class="c1"># One way</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>

    <span class="c1"># Another way</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;CPU it is!&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU it is!
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And many more!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="A-Quick-Note-about-Batching">A Quick Note about Batching<a class="anchor-link" href="#A-Quick-Note-about-Batching">&#182;</a></h2><p>In most ML applications we do mini-batch stochastic gradient descent instead of pure stochastic gradient descent.</p>
<p>Mini-batch SGD is a step between full gradient descent and stochastic gradient descent by computing the average gradient over a small number of examples.</p>
<p>In a nutshell, given <code>n</code> examples:</p>
<ul>
<li><strong>Full GD:</strong> dL/dw = average over all <code>n</code> examples. One step per <code>n</code> examples.</li>
<li><strong>SGD:</strong> dL/dw = point estimate over a single example. <code>n</code> steps per <code>n</code> examples.</li>
<li><strong>Mini-batch SGD:</strong> dL/dw = average over <code>m &lt;&lt; n</code> examples. <code>n / m</code> steps per <code>n</code> examples.</li>
</ul>
<p>Advantages of mini-batch SGD include a more stable gradient estimate and computational efficiency on modern hardware (exploiting parallelism gives sub-linear to constant time complexity, especially on GPU).</p>
<p>In PyTorch, batched tensors are represented as just another dimension. Most of the deep learning modules assume batched tensors as input (even if the batch size is just 1).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Batched matrix multiply</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="c1"># The same as for i in 1 ... 10, c_i = a[i].mm(b[i])</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([10, 5, 5])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Autograd:-Automatic-Differentiation!">Autograd: Automatic Differentiation!<a class="anchor-link" href="#Autograd:-Automatic-Differentiation!">&#182;</a></h2><p>Along with the flexible deep learning modules (to follow) this is the best part of using a package PyTorch.</p>
<p>What is autograd? It <em>automatically</em> computes <em>gradients</em>. All those complicated functions you might be using for your model need gradients for back-propagation. Autograd does this auto-magically! (Sorry, you still need to do this by hand for homework 4.)</p>
<p>Let's warmup.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># A tensor that will remember gradients</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([-0.1662], requires_grad=True)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>At first the 'grad' parameter is None:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>None
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's do an operation. Take y = e^x.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To run the gradient computing magic, call '.backward()' on a variable.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For all dependent variables {x_1, ..., x_n} that were used to compute y, dy/x_i is computed and stored in the x_i.grad field.</p>
<p>Here dy/dx = e^x = y. Let's see!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([0.8469]) tensor([0.8469], grad_fn=&lt;ExpBackward&gt;)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Important!</strong> Remember to zero gradients before subsequent calls to backwards.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Compute another thingy with x.</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="mi">2</span>
<span class="n">z</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

<span class="c1"># Should be 2! But it will be 2 + e^x.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([2.8469])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x_a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">x_b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">x_a</span> <span class="o">*</span> <span class="n">x_b</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span>
<span class="n">x2</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">x1</span>
<span class="n">x3</span> <span class="o">=</span> <span class="n">x2</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
<span class="n">x4</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">x3</span>
<span class="n">x5</span> <span class="o">=</span> <span class="n">x4</span><span class="o">.</span><span class="n">log</span><span class="p">()</span>
<span class="n">x6</span> <span class="o">=</span> <span class="n">x5</span> <span class="o">**</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">)</span>
<span class="n">x6</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_a</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_b</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>


<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([-2.4034])
tensor([-31.5575])
tensor([0.8933])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Also important!</strong> Under the hood PyTorch stores all the stuff required to compute gradients (call stack, cached values, etc). If you want to save a variable just to keep it around (say for logging or plotting) remember to call <code>.item()</code> to get the python value and free the PyTorch machinery memory.</p>
<p>You can stop auto-grad from running in the background by using the <code>torch.no_grad()</code> context manager.</p>
<div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">do_all_my_things</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Manual-Neural-Net-+-Autograd-SGD-Example-(read-this-while-studying-unit-3)">Manual Neural Net + Autograd SGD Example (read this while studying unit 3)<a class="anchor-link" href="#Manual-Neural-Net-+-Autograd-SGD-Example-(read-this-while-studying-unit-3)">&#182;</a></h2><p>Before we move on to the full PyTorch wrapper library, let's do a simple NN SGD example by hand.</p>
<p>We'll train a one hidden layer feed forward NN on a toy dataset.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[26]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Set our random seeds</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">):</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[27]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Get ourselves a simple dataset</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">make_classification</span>
<span class="n">set_seed</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_clusters_per_class</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of examples: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of features: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># Take a peak</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Number of examples: 100
Number of features: 2
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[28]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Convert data to PyTorch</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>

<span class="c1"># Gotcha: &quot;Expected object of scalar type Float but got scalar type Double&quot;</span>
<span class="c1"># If you see this it&#39;s because numpy defaults to Doubles whereas pytorch has floats.</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">Y</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We'll train a one layer neural net to classify this dataset. Let's define the parameter sizes:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[29]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Define dimensions</span>
<span class="n">num_feats</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">num_outputs</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Learning rate</span>
<span class="n">eta</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">num_steps</span> <span class="o">=</span> <span class="mi">1000</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And now run a few steps of SGD!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[30]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Input to hidden weights</span>
<span class="n">W1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_feats</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">b1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Hidden to output</span>
<span class="n">W2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_outputs</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_outputs</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Group parameters</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">[</span><span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">]</span>

<span class="c1"># Get random order</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

<span class="c1"># Keep running average losses for a learning curve?</span>
<span class="n">avg_loss</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Run!</span>
<span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">):</span>
    <span class="c1"># Get example</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">step</span> <span class="o">%</span> <span class="n">indices</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span>
    <span class="n">x_i</span><span class="p">,</span> <span class="n">y_i</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    
    <span class="c1"># Run example</span>
    <span class="n">hidden</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">W1</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x_i</span><span class="p">)</span> <span class="o">+</span> <span class="n">b1</span><span class="p">)</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">W2</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span> <span class="o">+</span> <span class="n">b2</span><span class="p">)</span>
    
    <span class="c1"># Compute loss binary cross entropy: -(y_i * log(y_hat) + (1 - y_i) * log(1 - y_hat))</span>
    <span class="c1"># Epsilon for numerical stability</span>
    <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-6</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">y_i</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_hat</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span><span class="o">.</span><span class="n">log</span><span class="p">()</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y_i</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y_hat</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span><span class="o">.</span><span class="n">log</span><span class="p">())</span>

    <span class="c1"># Add to our running average learning curve. Don&#39;t forget .item()!</span>
    <span class="k">if</span> <span class="n">step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">avg_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">old_avg</span> <span class="o">=</span> <span class="n">avg_loss</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">new_avg</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">+</span> <span class="n">old_avg</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">avg_loss</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">avg_loss</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">avg_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_avg</span><span class="p">)</span>
    
    <span class="c1"># Zero out all previous gradients</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
        <span class="c1"># It might start out as None</span>
        <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># In place</span>
            <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>

    <span class="c1"># Backward pass</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    
    <span class="c1"># Update parameters</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
        <span class="c1"># In place!</span>
        <span class="n">param</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span> <span class="o">-</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span>
    

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">),</span> <span class="n">avg_loss</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Step&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="torch.nn">torch.nn<a class="anchor-link" href="#torch.nn">&#182;</a></h2><p>The <code>nn</code> package is where all of the cool neural network stuff is. Layers, loss functions, etc.</p>
<p>Let's dive in.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Layers">Layers<a class="anchor-link" href="#Layers">&#182;</a></h3><p>Before we manually defined our linear layers. PyTorch has them for you as sub-classes of <code>nn.Module</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[31]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="c1"># Linear layer: in_features, out_features</span>
<span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">linear</span><span class="p">)</span>

<span class="c1"># Convolution layer: in_channels, out_channels, kernel_size, stride</span>
<span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">conv</span><span class="p">)</span>

<span class="c1"># RNN: num_inputs, num_hidden, num_layers</span>
<span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">rnn</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Linear(in_features=10, out_features=10, bias=True)
Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))
RNN(10, 10)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[33]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<span class="nb">print</span><span class="p">([</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">conv</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Parameter containing:
tensor([[-0.2087,  0.0624,  0.0927,  0.2812,  0.0016,  0.2136, -0.1054, -0.2304,
         -0.0307,  0.1642],
        [-0.1235, -0.2677, -0.1926,  0.0560,  0.3015,  0.0175, -0.2549, -0.1416,
          0.1605, -0.0995],
        [-0.0427,  0.2353,  0.1162,  0.1936,  0.2839, -0.1041,  0.0458, -0.2373,
          0.3143, -0.2120],
        [ 0.3006,  0.2895,  0.0688, -0.2734, -0.0102, -0.1303,  0.0969,  0.1788,
          0.1761,  0.1016],
        [-0.2423, -0.2660,  0.0934, -0.0694,  0.1478,  0.3073,  0.0955, -0.1904,
         -0.0913,  0.1948],
        [ 0.0300,  0.2156, -0.3031, -0.0390, -0.1542,  0.2403,  0.1383, -0.0424,
         -0.2934, -0.0373],
        [ 0.2564, -0.0085, -0.0131, -0.2924,  0.2504,  0.2616, -0.2541, -0.2243,
          0.0153, -0.1809],
        [-0.2588,  0.0992, -0.0820,  0.1096,  0.1257,  0.2816,  0.1879, -0.2973,
         -0.2548,  0.2535],
        [-0.2687,  0.1933, -0.1927,  0.2537,  0.1788, -0.2183, -0.2614, -0.1386,
         -0.1446, -0.1795],
        [ 0.2228,  0.0777, -0.0397, -0.0215,  0.1316,  0.0324, -0.0392,  0.2808,
          0.2182,  0.0222]], requires_grad=True)
[&#39;weight&#39;, &#39;bias&#39;]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[34]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Make our own model!</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># 1 input channel to 20 feature maps of 5x5 kernel. Stride 1.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># 20 input channels to 50 feature maps of 5x5 kernel. Stride 1.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Full connected of final 4x4 image to 500 features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="o">*</span><span class="mi">4</span><span class="o">*</span><span class="mi">50</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
        
        <span class="c1"># From 500 to 10 classes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="o">*</span><span class="mi">4</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Initialize it</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A note on convolution sizes:</p>
<p>Running a kernel over the image reduces the image height/length by kernel_size - 1.</p>
<p>Running a max pooling over the image reduces the image heigh/length by a factor of the kernel size.</p>
<p>So starting from a 28 x 28 image:</p>
<ul>
<li>Run 5x5 conv --&gt; 24 x 24</li>
<li>Apply 2x2 max pool --&gt; 12 x 12</li>
<li>Run 5x5 conv --&gt; 8 x 8</li>
<li>Apply 2x2 max pool --&gt; 4 x 4</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Optimizers">Optimizers<a class="anchor-link" href="#Optimizers">&#182;</a></h3><p>PyTorch handles all the optimizing too. There are several algorithms you can learn about later. Here's SGD:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[35]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>

<span class="c1"># Initialize with model parameters</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Updating is now as easy as:</p>
<div class="highlight"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">()</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
<h3 id="Full-train-and-test-loops">Full train and test loops<a class="anchor-link" href="#Full-train-and-test-loops">&#182;</a></h3><p>Let's look at a full train loop now.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[36]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tqdm</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
    <span class="c1"># For things like dropout</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    
    <span class="c1"># Avg loss</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="c1"># Iterate through dataset</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="c1"># Zero grad</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Forward pass</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        
        <span class="c1"># Negative log likelihood loss function</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

        <span class="c1"># Backward pass</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        
        <span class="c1"># Update</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="c1"># Print average loss</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train Epoch: </span><span class="si">{}</span><span class="se">\t</span><span class="s2"> Loss: </span><span class="si">{:.6f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Testing loops are similar.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[37]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">test_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="c1"># sum up batch loss</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># get the index of the max log-probability</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">test_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Test set: Average loss: </span><span class="si">{:.4f}</span><span class="s1">, Accuracy: </span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> (</span><span class="si">{:.0f}</span><span class="s1">%)</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">test_loss</span><span class="p">,</span> <span class="n">correct</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">),</span>
        <span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="MNIST">MNIST<a class="anchor-link" href="#MNIST">&#182;</a></h2><p>Just going to run mnist!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[38]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torchvision</span> <span class="k">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>

<span class="c1"># See the torch DataLoader for more details.</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">&#39;../data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                   <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                       <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                       <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
                   <span class="p">])),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">&#39;../data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                   <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                       <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                       <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
                   <span class="p">])),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
    <span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 1875/1875 [00:57&lt;00:00, 32.43it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train Epoch: 1	 Loss: 0.314105
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>  0%|          | 3/1875 [00:00&lt;01:03, 29.64it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test set: Average loss: 0.0967, Accuracy: 9701/10000 (97%)

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 1875/1875 [00:55&lt;00:00, 33.76it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train Epoch: 2	 Loss: 0.086927
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>  0%|          | 4/1875 [00:00&lt;00:58, 31.88it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test set: Average loss: 0.0590, Accuracy: 9818/10000 (98%)

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 1875/1875 [00:55&lt;00:00, 33.53it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train Epoch: 3	 Loss: 0.061660
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>  0%|          | 4/1875 [00:00&lt;00:58, 32.16it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test set: Average loss: 0.0493, Accuracy: 9839/10000 (98%)

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 1875/1875 [00:54&lt;00:00, 34.44it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train Epoch: 4	 Loss: 0.048638
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>  0%|          | 4/1875 [00:00&lt;00:57, 32.47it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test set: Average loss: 0.0403, Accuracy: 9874/10000 (99%)

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 1875/1875 [00:54&lt;00:00, 34.63it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train Epoch: 5	 Loss: 0.040329
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>  0%|          | 4/1875 [00:00&lt;00:55, 33.79it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test set: Average loss: 0.0337, Accuracy: 9885/10000 (99%)

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 1875/1875 [00:54&lt;00:00, 34.14it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train Epoch: 6	 Loss: 0.034306
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>  0%|          | 4/1875 [00:00&lt;00:58, 31.85it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test set: Average loss: 0.0372, Accuracy: 9876/10000 (99%)

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 1875/1875 [00:53&lt;00:00, 34.75it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train Epoch: 7	 Loss: 0.029963
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>  0%|          | 4/1875 [00:00&lt;00:56, 33.26it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test set: Average loss: 0.0337, Accuracy: 9889/10000 (99%)

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 1875/1875 [00:56&lt;00:00, 33.23it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train Epoch: 8	 Loss: 0.026079
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>  0%|          | 4/1875 [00:00&lt;00:56, 33.39it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test set: Average loss: 0.0349, Accuracy: 9887/10000 (99%)

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 1875/1875 [00:53&lt;00:00, 34.85it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train Epoch: 9	 Loss: 0.022861
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>  0%|          | 4/1875 [00:00&lt;00:56, 32.90it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test set: Average loss: 0.0374, Accuracy: 9877/10000 (99%)

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 1875/1875 [00:54&lt;00:00, 34.36it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train Epoch: 10	 Loss: 0.019654

Test set: Average loss: 0.0319, Accuracy: 9905/10000 (99%)

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
 


    </div>
  </div>

  </div>


  
    <footer class="footer hidden-print">
      <div class="container">
        <div class="col-md-4">
          <p>
            This website does not host notebooks, it only renders notebooks
            available on other websites.
          </p>
        </div>

        <div class="col-md-4">
          <p>
            Delivered by <a href="https://www.fastly.com/">Fastly</a>,
            Rendered by <a href="https://developer.rackspace.com/?nbviewer=awesome">Rackspace</a>
          </p>
          <p>
            nbviewer GitHub <a href="https://github.com/jupyter/nbviewer">repository</a>.
          </p>
        </div>

        <div class="col-md-4">
          
  
            
              <p>
                nbviewer version:
                <a href="https://github.com/jupyter/nbviewer/commit/07b0e305b3254e2280b29f20ceb96c058db2f775">
                  07b0e30
                </a>
              </p>
            
          
  
  <p>
    nbconvert version: <a href="https://github.com/jupyter/nbconvert/releases/tag/5.6.0">
      5.6.0
    </a>
  </p>
  

          
  
  
  <p>
    Rendered
    <span class='date' data-date='Tue, 11 Feb 2020 23:32:52 UTC' title='Tue, 11 Feb 2020 23:32:52 UTC'>(Tue, 11 Feb 2020 23:32:52 UTC)</span>
  </p>
  

        </div>
      </div>
    </footer>
  

  <script src="/static/components/bootstrap/js/bootstrap.min.js?v=5869c96cc8f19086aee625d670d741f9"></script>
  <script src="/static/components/headroom.js/dist/headroom.min.js?v=b0a311ea668f8e768ea375f4a7abb81c"></script>
  <script src="/static/components/headroom.js/dist/jQuery.headroom.min.js?v=f3a1bae118315d0c234afc74dc6aab71"></script>

  
  
  <script>
    $(function(){ $("#menubar").headroom({
      tolerance: 5,
      offset: 205,
      classes: {
        initial: "animated",
        pinned: "slideInDown",
        unpinned: "slideOutUp"
      }
    })});
  </script>


  
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-52617120-5', 'auto',
       {'storage': 'none'});
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
  </script>
  
  <script>
    require({
        paths: {
          moment: "/static/components/moment/min/moment.min.js?v=89f87298ad94aa1e6b92f42eb66da043"
        }
      }, ["moment"], function(moment){
      var date = $("footer .date"),
        m = moment(new Date(date.data('date'))),
        update = function(){ date.text(m.fromNow()); };
      setInterval(update, 61*1000);
      update();
      var w = $(window).scroll(function(event){
        $("body").toggleClass("scrolled", w.scrollTop() > 0);
      });
    });
  </script>

  <!--NEW RELIC Stop Perf Measurement-->
  
  <!--NEW RELIC End-->
</body>
</html>